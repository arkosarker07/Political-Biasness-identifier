{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkosarker07/Political-Biasness-identifier/blob/main/BiasDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt4ikO1QBXnV",
        "collapsed": true,
        "outputId": "ea2219ca-5fe3-4410-cfaf-b7b89e63d78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IndicTrans2' already exists and is not an empty directory.\n",
            "/content/IndicTrans2/huggingface_interface\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
            "fatal: destination path 'IndicTransToolkit' already exists and is not an empty directory.\n",
            "/content/IndicTrans2/huggingface_interface/IndicTransToolkit\n",
            "Obtaining file:///content/IndicTrans2/huggingface_interface/IndicTransToolkit\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from indictranstoolkit==1.1.1) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (from indictranstoolkit==1.1.1) (0.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from indictranstoolkit==1.1.1) (4.53.3)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (from indictranstoolkit==1.1.1) (2.5.1)\n",
            "Requirement already satisfied: indic-nlp-library-itt in /usr/local/lib/python3.11/dist-packages (from indictranstoolkit==1.1.1) (0.1.1)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.2.2)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->indictranstoolkit==1.1.1) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library-itt->indictranstoolkit==1.1.1) (3.0.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu->indictranstoolkit==1.1.1) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->indictranstoolkit==1.1.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->indictranstoolkit==1.1.1) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->indictranstoolkit==1.1.1) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->indictranstoolkit==1.1.1) (5.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->indictranstoolkit==1.1.1) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->indictranstoolkit==1.1.1) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses->indictranstoolkit==1.1.1) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->indictranstoolkit==1.1.1) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->indictranstoolkit==1.1.1) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->indictranstoolkit==1.1.1) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->indictranstoolkit==1.1.1) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->indictranstoolkit==1.1.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->indictranstoolkit==1.1.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->indictranstoolkit==1.1.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->indictranstoolkit==1.1.1) (2025.7.14)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.11/dist-packages (from sphinx-rtd-theme->indic-nlp-library-itt->indictranstoolkit==1.1.1) (4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-itt->indictranstoolkit==1.1.1) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->indictranstoolkit==1.1.1) (3.0.2)\n",
            "Building wheels for collected packages: indictranstoolkit\n",
            "  Building editable for indictranstoolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indictranstoolkit: filename=indictranstoolkit-1.1.1-0.editable-cp311-cp311-linux_x86_64.whl size=6523 sha256=19d78e3c8b3ff6a220dc0505e2e7557688fdf541cb5b44c539b3292f2d43168b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5s1cs759/wheels/cd/d6/69/93b087e184d23ff1d423e9092f2d3bb99a8726a668f984156e\n",
            "Successfully built indictranstoolkit\n",
            "Installing collected packages: indictranstoolkit\n",
            "  Attempting uninstall: indictranstoolkit\n",
            "    Found existing installation: indictranstoolkit 1.1.1\n",
            "    Uninstalling indictranstoolkit-1.1.1:\n",
            "      Successfully uninstalled indictranstoolkit-1.1.1\n",
            "Successfully installed indictranstoolkit-1.1.1\n",
            "/content/IndicTrans2/huggingface_interface\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git\n",
        "%cd /content/IndicTrans2/huggingface_interface\n",
        "!pip install -r requirements.txt\n",
        "!pip install sentencepiece bitsandbytes scipy accelerate\n",
        "!git clone https://github.com/VarunGumma/IndicTransToolkit.git\n",
        "%cd IndicTransToolkit\n",
        "!pip install --editable ./\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "import gradio as gr\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from IndicTransToolkit.processor import IndicProcessor\n",
        "\n",
        "# Setup device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 2  # Reduced for memory safety\n",
        "src_lang, tgt_lang = \"ben_Beng\", \"eng_Latn\"\n",
        "\n",
        "# Initialize model + tokenizer with 8-bit quantization\n",
        "def initialize_model_and_tokenizer(ckpt_dir, quantization=\"8-bit\"):\n",
        "    if quantization == \"4-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    elif quantization == \"8-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    else:\n",
        "        qconfig = None\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        ckpt_dir,\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        quantization_config=qconfig,\n",
        "    )\n",
        "\n",
        "    if qconfig is None:\n",
        "        model = model.to(DEVICE)\n",
        "        if DEVICE == \"cuda\":\n",
        "            model.half()\n",
        "\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Smart chunking\n",
        "def split_into_chunks(text, max_chars=300):\n",
        "    sentences = re.split(r'(?<=[ред!?])\\s+', text.strip())\n",
        "    chunks = []\n",
        "    current = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current) + len(sentence) <= max_chars:\n",
        "            current += \" \" + sentence\n",
        "        else:\n",
        "            if current:\n",
        "                chunks.append(current.strip())\n",
        "            current = sentence\n",
        "    if current:\n",
        "        chunks.append(current.strip())\n",
        "    return chunks\n",
        "\n",
        "# Batch translation\n",
        "def batch_translate(input_sentences, model, tokenizer, ip, mode=\"Fast\"):\n",
        "    translations = []\n",
        "    beam_size = 3 if mode == \"Fast\" else 5\n",
        "    max_length = 200 if mode == \"Fast\" else 256\n",
        "\n",
        "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
        "        batch = input_sentences[i: i + BATCH_SIZE]\n",
        "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                generated_tokens = model.generate(\n",
        "                    **inputs,\n",
        "                    use_cache=True,\n",
        "                    min_length=0,\n",
        "                    max_length=max_length,\n",
        "                    num_beams=beam_size,\n",
        "                    num_return_sequences=1,\n",
        "                )\n",
        "\n",
        "            generated_tokens = tokenizer.batch_decode(\n",
        "                generated_tokens,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=True,\n",
        "            )\n",
        "\n",
        "            translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "        except Exception as e:\n",
        "            translations += [\"[Translation Failed]\"] * len(batch)\n",
        "\n",
        "        del inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return translations\n",
        "\n",
        "# Load model with 8-bit quantization\n",
        "quantization = \"8-bit\"\n",
        "indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-1B\"\n",
        "indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, quantization)\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Bias classification model\n",
        "bias_pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"matous-volf/political-leaning-deberta-large\",\n",
        "    tokenizer=\"microsoft/deberta-v3-large\",\n",
        ")\n",
        "\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"Left\",\n",
        "    \"LABEL_1\": \"Center\",\n",
        "    \"LABEL_2\": \"Right\"\n",
        "}\n",
        "\n",
        "# Main function\n",
        "def translate_and_classify(bn_text, mode):\n",
        "    if not bn_text.strip():\n",
        "        return \"Please enter Bangla news content.\", \"\", \"\"\n",
        "\n",
        "    bn_sents = split_into_chunks(bn_text.strip(), max_chars=300)\n",
        "    translations = batch_translate(bn_sents, indic_en_model, indic_en_tokenizer, ip, mode)\n",
        "    english_text = \" \".join(translations)\n",
        "\n",
        "    if \"[Translation Failed]\" in translations:\n",
        "        return \"Translation failed for some parts.\", \"\", english_text\n",
        "\n",
        "    result = bias_pipe(english_text)[0]\n",
        "    label = label_map.get(result[\"label\"], result[\"label\"])\n",
        "    score = result[\"score\"]\n",
        "\n",
        "    return f\"{label}\", f\"{score:.2%}\", english_text\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Bangla & English News Bias Detector\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            bangla_input = gr.Textbox(label=\"Paste News Article\", lines=10, placeholder=\"Here...\")\n",
        "            mode_selector = gr.Radio([\"Fast\", \"Accurate\"], value=\"Fast\", label=\"Translation Mode\")\n",
        "            submit_btn = gr.Button(\"Analyze Bias\")\n",
        "\n",
        "        with gr.Column():\n",
        "            bias_output = gr.Textbox(label=\"Bias\", interactive=False)\n",
        "            score_output = gr.Textbox(label=\"Confidence\", interactive=False)\n",
        "            eng_translation = gr.Textbox(label=\"English Translation\", lines=10, interactive=False)\n",
        "\n",
        "    submit_btn.click(translate_and_classify, inputs=[bangla_input, mode_selector], outputs=[bias_output, score_output, eng_translation])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "V6YyT3T1u2ZP",
        "outputId": "ad241933-4e12-4653-b35c-39b1df87c09c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://989c5564a59335dc66.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://989c5564a59335dc66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOm0WNOD2SAqOCWAxlVEYn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}